{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPOC Code Generation (Colab GPU)\n",
    "\n",
    "Generate code on GPU, then download results for local evaluation.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-907070862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls && pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'spoc' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Clone repo (first time only)\n",
    "!git clone https://github.com/tlebryk/spoc.git\n",
    "# %cd YOUR_REPO/spoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch accelerate pandas tqdm sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-24 23:51:50--  https://sumith1896.github.io/spoc/data/spoc.zip\n",
      "Resolving sumith1896.github.io (sumith1896.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to sumith1896.github.io (sumith1896.github.io)|185.199.108.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9960355 (9.5M) [application/x-zip-compressed]\n",
      "Saving to: ‘spoc.zip’\n",
      "\n",
      "spoc.zip            100%[===================>]   9.50M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2025-11-24 23:51:50 (107 MB/s) - ‘spoc.zip’ saved [9960355/9960355]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download SPOC data (if not in repo)\n",
    "!wget https://sumith1896.github.io/spoc/data/spoc.zip\n",
    "!unzip -q spoc.zip && mv spoc/* . && rm -rf spoc spoc.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "from data_loader import SPOCDataLoader\n",
    "from inference import CodeGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Code (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPOC Code Generation Evaluation\n",
      "================================================================================\n",
      "\n",
      "Model: Qwen/Qwen2.5-Coder-0.5B\n",
      "Split: testp\n",
      "N samples: 2\n",
      "Temperature: 0.2\n",
      "Using hidden test cases\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Loading data...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Loaded 1815 programs from testp\n",
      "✓ Using 2 programs for evaluation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Generating code...\n",
      "--------------------------------------------------------------------------------\n",
      "Loading model: Qwen/Qwen2.5-Coder-0.5B\n",
      "Device: cpu\n",
      "tokenizer_config.json: 7.23kB [00:00, 17.1MB/s]\n",
      "vocab.json: 2.78MB [00:00, 49.9MB/s]\n",
      "merges.txt: 1.67MB [00:00, 118MB/s]\n",
      "tokenizer.json: 7.03MB [00:00, 138MB/s]\n",
      "config.json: 100% 659/659 [00:00<00:00, 4.19MB/s]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "2025-11-24 23:54:02.974276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764028443.313369   38967 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764028443.319896   38967 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764028443.339114   38967 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764028443.339158   38967 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764028443.339163   38967 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764028443.339168   38967 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-24 23:54:03.344984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "model.safetensors: 100% 988M/988M [00:11<00:00, 83.0MB/s] \n",
      "generation_config.json: 100% 139/139 [00:00<00:00, 945kB/s]\n",
      "✓ Model loaded successfully\n",
      "Generating code for 2 programs...\n",
      "Generating: 100% 2/2 [02:44<00:00, 82.14s/it]\n",
      "✓ Successfully generated 2/2 programs\n",
      "✓ Results saved to outputs/generations_20251124_235356.json\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Evaluating...\n",
      "--------------------------------------------------------------------------------\n",
      "Computing BLEU scores...\n",
      "✓ BLEU: 40.00\n",
      "\n",
      "Compiling and testing programs...\n",
      "Evaluating 2 programs...\n",
      "Evaluating 2/2: 1007A_42149991_36\n",
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "Lexical Similarity:\n",
      "  BLEU: 40.00\n",
      "\n",
      "Compilation & Correctness:\n",
      "  CompAcc (Compilation Accuracy):   100.00%\n",
      "  FCorrAcc (Functional Correctness): 50.00%\n",
      "  Pass@1:                            100.00%\n",
      "\n",
      "Details:\n",
      "  Total programs:    2\n",
      "  Compiled:          2\n",
      "  Functionally correct: 1\n",
      "  Total problems:    1\n",
      "  Correct problems:  1\n",
      "\n",
      "================================================================================\n",
      "✓ Full results saved to outputs/evaluation_20251124_235356.json\n",
      "\n",
      "✓ Metrics summary saved to outputs/metrics_summary_20251124_235356.txt\n",
      "\n",
      "================================================================================\n",
      "Evaluation complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python run_eval.py --n-samples 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_20251124_235356.json   metrics_summary_20251124_235356.txt\n",
      "generations_20251124_235356.json\n"
     ]
    }
   ],
   "source": [
    "!ls outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
